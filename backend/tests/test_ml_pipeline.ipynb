{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0e7f36c",
   "metadata": {},
   "source": [
    "# TowerGuard ML Pipeline Validation Notebook\n",
    "\n",
    "**Project:** TowerGuard - Water Tower Environmental Health Monitoring  \n",
    "**Track:** Data-Driven Impact Measurement (Wangari Maathai Hackathon)  \n",
    "**Objective:** Validate end-to-end ML pipeline (NDVI ‚Üí Features ‚Üí Scoring) on 3 real water towers\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. Feature extraction from Sentinel-2 satellite data\n",
    "2. Environmental feature gathering (rainfall, temperature, elevation)\n",
    "3. Rule-based health score computation\n",
    "4. Visualization and interpretation of results\n",
    "\n",
    "**Test Sites:** Mau, Aberdare, Mt. Elgon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0358a3ea",
   "metadata": {},
   "source": [
    "## Section 1: Set Up Development Environment\n",
    "\n",
    "Import essential libraries and configure logging for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c570feba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add backend/ml to path for imports\n",
    "sys.path.insert(0, str(Path().resolve().parent.parent / 'ml'))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ML pipeline modules\n",
    "from utils import logger, setup_logger, build_feature_vector_from_site_features, FEATURE_FIELDS\n",
    "from features import SiteFeatures, extract_features_for_site\n",
    "from scoring import compute_health_score, create_prediction_for_site_features, SCORING_RULES, HEALTH_CATEGORIES\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Configure logging\n",
    "logger = setup_logger(name=\"validation\", log_dir=str(Path().resolve().parent.parent / 'logs'))\n",
    "logger.info(\"=\" * 80)\n",
    "logger.info(\"Starting TowerGuard ML Pipeline Validation\")\n",
    "logger.info(\"=\" * 80)\n",
    "\n",
    "print(\"‚úì Environment configured successfully\")\n",
    "print(f\"‚úì Logging to: backend/logs/ml_pipeline.log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b92a7a",
   "metadata": {},
   "source": [
    "## Section 2: Define Test Sites Configuration\n",
    "\n",
    "Define the 3 water towers for validation with mock features (in production, these would come from actual Sentinel-2 data and climate APIs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f842550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test sites with mock features\n",
    "# In production, these would use actual Sentinel-2 data and climate APIs\n",
    "\n",
    "test_sites = {\n",
    "    'mau': {\n",
    "        'site_id': 'mau',\n",
    "        'name': 'Mau Water Tower',\n",
    "        'latitude': -0.5,\n",
    "        'longitude': 35.0,\n",
    "        'description': 'Large highland forest complex in Western Kenya',\n",
    "        # Mock features (in production: from NDVI computation and climate APIs)\n",
    "        'features': {\n",
    "            'ndvi_mean': 0.62,        # Good vegetation\n",
    "            'ndvi_std': 0.18,         # Meets low variance threshold\n",
    "            'rainfall_mm': 1850.0,    # High rainfall\n",
    "            'temp_mean_c': 18.5,      # Good temperature\n",
    "            'elevation_m': 2400.0     # Within optimal range\n",
    "        }\n",
    "    },\n",
    "    'aberdare': {\n",
    "        'site_id': 'aberdare',\n",
    "        'name': 'Aberdare Water Tower',\n",
    "        'latitude': -0.35,\n",
    "        'longitude': 36.8,\n",
    "        'description': 'Mountain range forming part of the Eastern Rift Valley',\n",
    "        'features': {\n",
    "            'ndvi_mean': 0.55,        # Good vegetation\n",
    "            'ndvi_std': 0.22,         # Slightly above threshold\n",
    "            'rainfall_mm': 980.0,     # Moderate rainfall\n",
    "            'temp_mean_c': 16.2,      # Within optimal range\n",
    "            'elevation_m': 2700.0     # Within optimal range\n",
    "        }\n",
    "    },\n",
    "    'mt_elgon': {\n",
    "        'site_id': 'mt_elgon',\n",
    "        'name': 'Mt. Elgon Water Tower',\n",
    "        'latitude': 1.1,\n",
    "        'longitude': 34.6,\n",
    "        'description': 'Extinct volcano on Kenya-Uganda border',\n",
    "        'features': {\n",
    "            'ndvi_mean': 0.48,        # Below optimal vegetation\n",
    "            'ndvi_std': 0.25,         # High variance\n",
    "            'rainfall_mm': 1100.0,    # Adequate rainfall\n",
    "            'temp_mean_c': 14.8,      # Cool but acceptable\n",
    "            'elevation_m': 3100.0     # Above optimal elevation range\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Display test sites summary\n",
    "print(\"=\" * 80)\n",
    "print(\"TEST SITES CONFIGURATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for site_id, site_data in test_sites.items():\n",
    "    print(f\"\\nüìç {site_data['name']} ({site_id.upper()})\")\n",
    "    print(f\"   Location: {site_data['latitude']:.2f}¬∞, {site_data['longitude']:.2f}¬∞\")\n",
    "    print(f\"   Description: {site_data['description']}\")\n",
    "    print(f\"   Features:\")\n",
    "    for feat, value in site_data['features'].items():\n",
    "        units = {'ndvi_mean': '', 'ndvi_std': '', 'rainfall_mm': 'mm', 'temp_mean_c': '¬∞C', 'elevation_m': 'm'}\n",
    "        print(f\"      ‚Ä¢ {feat}: {value} {units[feat]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9631a39",
   "metadata": {},
   "source": [
    "## Section 3: Feature Vector Construction & Validation\n",
    "\n",
    "Build feature vectors from mock features and validate against schema constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de163871",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import validate_feature_vector\n",
    "\n",
    "# Build feature vectors for all sites\n",
    "print(\"FEATURE VECTOR CONSTRUCTION & VALIDATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "feature_vectors = {}\n",
    "\n",
    "for site_id, site_data in test_sites.items():\n",
    "    features_dict = site_data['features']\n",
    "    \n",
    "    # Build feature vector\n",
    "    result = build_feature_vector_from_site_features(features_dict)\n",
    "    feature_vectors[site_id] = result['feature_vector']\n",
    "    \n",
    "    # Validate\n",
    "    validation = validate_feature_vector(result['feature_vector'])\n",
    "    \n",
    "    print(f\"\\nüìä {site_id.upper()}\")\n",
    "    print(f\"   Feature Vector: {result['feature_vector']}\")\n",
    "    print(f\"   Complete: {result['is_complete']}\")\n",
    "    print(f\"   Valid: {validation['valid']}\")\n",
    "    \n",
    "    if validation['warnings']:\n",
    "        for warning in validation['warnings']:\n",
    "            print(f\"   ‚ö†Ô∏è  {warning}\")\n",
    "    \n",
    "    if validation['errors']:\n",
    "        for error in validation['errors']:\n",
    "            print(f\"   ‚ùå {error}\")\n",
    "\n",
    "# Create feature dataframe for easy comparison\n",
    "feature_df = pd.DataFrame(\n",
    "    {site_id: feature_vectors[site_id] for site_id in test_sites.keys()},\n",
    "    index=FEATURE_FIELDS\n",
    ")\n",
    "\n",
    "print(\"\\n\\nFEATURE MATRIX (all sites)\")\n",
    "print(feature_df.to_string())\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107db451",
   "metadata": {},
   "source": [
    "## Section 4: Rule-Based Health Score Computation\n",
    "\n",
    "Apply scoring rules to each site and compute health scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b167ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nDISPLAYING SCORING RULES\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nRules defined in scoring.py:\\n\")\n",
    "\n",
    "for i, rule in enumerate(SCORING_RULES, 1):\n",
    "    print(f\"{i}. {rule.condition}\")\n",
    "    print(f\"   Points if met: +{rule.points_if_met}\")\n",
    "    print()\n",
    "\n",
    "# Compute health scores\n",
    "predictions = {}\n",
    "\n",
    "for site_id, site_data in test_sites.items():\n",
    "    # Create SiteFeatures object\n",
    "    features_obj = SiteFeatures(\n",
    "        site_id=site_id,\n",
    "        ndvi_mean=site_data['features']['ndvi_mean'],\n",
    "        ndvi_std=site_data['features']['ndvi_std'],\n",
    "        rainfall_mm=site_data['features']['rainfall_mm'],\n",
    "        temp_mean_c=site_data['features']['temp_mean_c'],\n",
    "        elevation_m=site_data['features']['elevation_m']\n",
    "    )\n",
    "    \n",
    "    # Compute health score\n",
    "    score_result = compute_health_score(features_obj)\n",
    "    predictions[site_id] = score_result\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(f\"SITE: {site_data['name'].upper()} ({site_id})\")\n",
    "    print(f\"{'=' * 80}\")\n",
    "    \n",
    "    category = score_result['category_name']\n",
    "    score = score_result['health_score']\n",
    "    raw_points = score_result['raw_points']\n",
    "    max_points = score_result['max_points']\n",
    "    \n",
    "    print(f\"\\nüìä HEALTH SCORE: {score:.1%} ({category})\")\n",
    "    print(f\"   Points: {raw_points:.0f} / {max_points} points\\n\")\n",
    "    \n",
    "    print(\"RULE BREAKDOWN:\")\n",
    "    for rule_result in score_result['rule_results']:\n",
    "        status = \"‚úì\" if rule_result['met'] else \"‚úó\"\n",
    "        rule_text = rule_result['rule']\n",
    "        points = rule_result['points_earned']\n",
    "        explanation = rule_result['explanation']\n",
    "        \n",
    "        print(f\"  {status} {rule_text}\")\n",
    "        print(f\"     ‚Üí {explanation} ({points:.0f} pts)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d2d549",
   "metadata": {},
   "source": [
    "## Section 5: Prediction Output & Interpretation\n",
    "\n",
    "Generate comprehensive prediction outputs with human-readable interpretations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc731f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive predictions\n",
    "full_predictions = {}\n",
    "\n",
    "for site_id, site_data in test_sites.items():\n",
    "    # Create SiteFeatures object\n",
    "    features_obj = SiteFeatures(\n",
    "        site_id=site_id,\n",
    "        ndvi_mean=site_data['features']['ndvi_mean'],\n",
    "        ndvi_std=site_data['features']['ndvi_std'],\n",
    "        rainfall_mm=site_data['features']['rainfall_mm'],\n",
    "        temp_mean_c=site_data['features']['temp_mean_c'],\n",
    "        elevation_m=site_data['features']['elevation_m']\n",
    "    )\n",
    "    \n",
    "    # Create full prediction with interpretation\n",
    "    metadata = {\n",
    "        'site_name': site_data['name'],\n",
    "        'location': f\"{site_data['latitude']:.2f}¬∞, {site_data['longitude']:.2f}¬∞\",\n",
    "        'description': site_data['description'],\n",
    "        'data_sources': {\n",
    "            'ndvi': 'Sentinel-2 (Mock)',\n",
    "            'rainfall': 'WorldClim (Mock)',\n",
    "            'temperature': 'WorldClim (Mock)',\n",
    "            'elevation': 'SRTM (Mock)'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    prediction = create_prediction_for_site_features(features_obj, metadata)\n",
    "    full_predictions[site_id] = prediction\n",
    "    \n",
    "    # Display interpretation\n",
    "    print(prediction['explanation'])\n",
    "    print(\"\\n\" + \"=\" * 80 + \"\\n\")\n",
    "\n",
    "# Save predictions to JSON files\n",
    "output_dir = Path().resolve().parent.parent / 'docs' / 'examples'\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for site_id, prediction in full_predictions.items():\n",
    "    filepath = output_dir / f\"prediction_{site_id}.json\"\n",
    "    with open(filepath, 'w') as f:\n",
    "        json.dump(prediction, f, indent=2)\n",
    "    print(f\"‚úì Saved prediction: {filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15eb0bd4",
   "metadata": {},
   "source": [
    "## Section 6: Comparative Analysis & Visualization\n",
    "\n",
    "Visualize and compare health scores across the 3 water towers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7923b5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison dataframe\n",
    "comparison_data = []\n",
    "\n",
    "for site_id, prediction in full_predictions.items():\n",
    "    site_data = test_sites[site_id]\n",
    "    comparison_data.append({\n",
    "        'Site': site_data['name'],\n",
    "        'Health Score': prediction['health_score'],\n",
    "        'Category': prediction['category'],\n",
    "        'Raw Points': prediction['raw_points'],\n",
    "        'NDVI Mean': prediction['features']['ndvi_mean'],\n",
    "        'Rainfall (mm)': prediction['features']['rainfall_mm'],\n",
    "        'Temp (¬∞C)': prediction['features']['temp_mean_c'],\n",
    "        'Elevation (m)': prediction['features']['elevation_m']\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "print(\"\\nCOMPARATIVE SUMMARY - ALL SITES\")\n",
    "print(\"=\" * 100)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# Create visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "fig.suptitle('TowerGuard Water Tower Health Metrics Comparison', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plot 1: Health Scores\n",
    "ax1 = axes[0, 0]\n",
    "colors = ['#d62728' if score < 0.4 else '#ff7f0e' if score < 0.6 else '#2ca02c' \n",
    "          for score in comparison_df['Health Score']]\n",
    "bars1 = ax1.barh(comparison_df['Site'], comparison_df['Health Score'], color=colors, alpha=0.8)\n",
    "ax1.set_xlabel('Health Score (0-1)', fontweight='bold')\n",
    "ax1.set_title('Overall Health Scores')\n",
    "ax1.set_xlim(0, 1)\n",
    "for i, v in enumerate(comparison_df['Health Score']):\n",
    "    ax1.text(v + 0.02, i, f'{v:.1%}', va='center', fontweight='bold')\n",
    "\n",
    "# Plot 2: NDVI Mean\n",
    "ax2 = axes[0, 1]\n",
    "bars2 = ax2.bar(comparison_df['Site'], comparison_df['NDVI Mean'], color='green', alpha=0.7)\n",
    "ax2.axhline(y=0.5, color='red', linestyle='--', linewidth=2, label='Rule Threshold (0.5)')\n",
    "ax2.set_ylabel('NDVI Mean', fontweight='bold')\n",
    "ax2.set_title('Vegetation Index (NDVI)')\n",
    "ax2.set_ylim(0, 1)\n",
    "ax2.legend()\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Plot 3: Rainfall\n",
    "ax3 = axes[1, 0]\n",
    "bars3 = ax3.bar(comparison_df['Site'], comparison_df['Rainfall (mm)'], color='blue', alpha=0.7)\n",
    "ax3.axhline(y=120, color='red', linestyle='--', linewidth=2, label='Rule Threshold (120 mm)')\n",
    "ax3.set_ylabel('Rainfall (mm)', fontweight='bold')\n",
    "ax3.set_title('Annual Rainfall')\n",
    "ax3.legend()\n",
    "ax3.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Plot 4: Temperature & Elevation\n",
    "ax4 = axes[1, 1]\n",
    "x_pos = np.arange(len(comparison_df['Site']))\n",
    "width = 0.35\n",
    "\n",
    "# Normalize temperature and elevation for comparison\n",
    "temp_normalized = (comparison_df['Temp (¬∞C)'] - comparison_df['Temp (¬∞C)'].min()) / (comparison_df['Temp (¬∞C)'].max() - comparison_df['Temp (¬∞C)'].min())\n",
    "elev_normalized = (comparison_df['Elevation (m)'] - comparison_df['Elevation (m)'].min()) / (comparison_df['Elevation (m)'].max() - comparison_df['Elevation (m)'].min())\n",
    "\n",
    "bars4a = ax4.bar(x_pos - width/2, temp_normalized, width, label='Temperature (normalized)', alpha=0.8)\n",
    "bars4b = ax4.bar(x_pos + width/2, elev_normalized, width, label='Elevation (normalized)', alpha=0.8)\n",
    "\n",
    "ax4.set_ylabel('Normalized Value', fontweight='bold')\n",
    "ax4.set_title('Temperature & Elevation (Normalized)')\n",
    "ax4.set_xticks(x_pos)\n",
    "ax4.set_xticklabels(comparison_df['Site'], rotation=45)\n",
    "ax4.legend()\n",
    "ax4.set_ylim(0, 1.1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'health_metrics_comparison.png', dpi=300, bbox_inches='tight')\n",
    "print(f\"\\n‚úì Saved visualization: {output_dir / 'health_metrics_comparison.png'}\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fe522e",
   "metadata": {},
   "source": [
    "## Section 7: Feature Vector Visualization\n",
    "\n",
    "Display feature vectors in matrix form with heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4d02e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature vector heatmap\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Normalize feature vectors for visualization (0-1 scale per feature)\n",
    "feature_matrix = feature_df.copy()\n",
    "for idx in feature_matrix.index:\n",
    "    min_val = feature_matrix.loc[idx].min()\n",
    "    max_val = feature_matrix.loc[idx].max()\n",
    "    if max_val > min_val:\n",
    "        feature_matrix.loc[idx] = (feature_matrix.loc[idx] - min_val) / (max_val - min_val)\n",
    "\n",
    "# Create heatmap\n",
    "sns.heatmap(\n",
    "    feature_matrix,\n",
    "    annot=feature_df.values,\n",
    "    fmt='.3f',\n",
    "    cmap='RdYlGn',\n",
    "    cbar_kws={'label': 'Normalized Value'},\n",
    "    ax=ax,\n",
    "    vmin=0,\n",
    "    vmax=1,\n",
    "    linewidths=0.5,\n",
    "    cbar=True\n",
    ")\n",
    "\n",
    "ax.set_title('Feature Vector Heatmap (Values shown, Color = Normalized)', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Water Tower Sites', fontweight='bold')\n",
    "ax.set_ylabel('Features', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'feature_vectors_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "print(f\"‚úì Saved visualization: {output_dir / 'feature_vectors_heatmap.png'}\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nFEATURE VECTOR VALUES (Raw)\")\n",
    "print(feature_df.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2122e5e6",
   "metadata": {},
   "source": [
    "## Section 8: Scoring Breakdown Comparison\n",
    "\n",
    "Detailed per-rule comparison across all sites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4f8941",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nSCORING BREAKDOWN BY SITE\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# Create scoring breakdown table\n",
    "scoring_data = []\n",
    "\n",
    "for site_id, prediction in full_predictions.items():\n",
    "    site_name = test_sites[site_id]['name']\n",
    "    \n",
    "    for rule_idx, rule_result in enumerate(prediction['rule_breakdown'].items()):\n",
    "        rule_name, rule_data = rule_result\n",
    "        scoring_data.append({\n",
    "            'Site': site_name,\n",
    "            'Rule': rule_name,\n",
    "            'Value': rule_data['value'],\n",
    "            'Met': '‚úì' if rule_data['met'] else '‚úó',\n",
    "            'Points': rule_data['points']\n",
    "        })\n",
    "\n",
    "scoring_df = pd.DataFrame(scoring_data)\n",
    "\n",
    "# Pivot to see rules as columns\n",
    "scoring_pivot = scoring_df.pivot_table(\n",
    "    index='Site',\n",
    "    columns='Rule',\n",
    "    values='Points',\n",
    "    aggfunc='first'\n",
    ")\n",
    "\n",
    "print(\"\\nPOINTS PER RULE (all sites)\")\n",
    "print(scoring_pivot.to_string())\n",
    "\n",
    "# Summary by site\n",
    "print(\"\\n\\nTOTAL POINTS BY SITE\")\n",
    "print(\"-\" * 50)\n",
    "for site_id, prediction in full_predictions.items():\n",
    "    site_name = test_sites[site_id]['name']\n",
    "    total_pts = sum(rule['points'] for rule in prediction['rule_breakdown'].values())\n",
    "    health_score = prediction['health_score']\n",
    "    category = prediction['category']\n",
    "    print(f\"{site_name:30} {total_pts:5.0f} pts ({health_score:.1%}) - {category}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b365041",
   "metadata": {},
   "source": [
    "## Section 9: Validation Summary & Deliverables\n",
    "\n",
    "Final validation results and artifacts summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c1c0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"VALIDATION SUMMARY\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "print(\"\\n‚úì COMPLETED TASKS:\")\n",
    "print(\"  1. ‚úì Set up development environment with all dependencies\")\n",
    "print(\"  2. ‚úì Loaded and configured 3 water tower test sites (Mau, Aberdare, Mt. Elgon)\")\n",
    "print(\"  3. ‚úì Built feature vectors with schema validation\")\n",
    "print(\"  4. ‚úì Applied all 5 rule-based scoring rules\")\n",
    "print(\"  5. ‚úì Computed health scores (0-1 scale) and categories\")\n",
    "print(\"  6. ‚úì Generated human-readable interpretations\")\n",
    "print(\"  7. ‚úì Created visualizations for comparative analysis\")\n",
    "print(\"  8. ‚úì Validated feature completeness and ranges\")\n",
    "\n",
    "print(\"\\nüìä VALIDATION RESULTS:\")\n",
    "\n",
    "for site_id, prediction in full_predictions.items():\n",
    "    site_name = test_sites[site_id]['name']\n",
    "    score = prediction['health_score']\n",
    "    category = prediction['category']\n",
    "    missing = len(prediction['missing_features'])\n",
    "    \n",
    "    print(f\"\\n  {site_name}:\")\n",
    "    print(f\"    ‚Ä¢ Health Score: {score:.1%} ({category})\")\n",
    "    print(f\"    ‚Ä¢ Missing Features: {missing}/5\")\n",
    "    if missing > 0:\n",
    "        print(f\"      {prediction['missing_features']}\")\n",
    "\n",
    "print(\"\\nüìÅ DELIVERABLES (saved to docs/examples/):\")\n",
    "\n",
    "# List all output files\n",
    "output_files = sorted(output_dir.glob('*'))\n",
    "for filepath in output_files:\n",
    "    print(f\"  ‚Ä¢ {filepath.name}\")\n",
    "\n",
    "print(\"\\nüìù PIPELINE COMPONENTS:\")\n",
    "print(\"  ‚úì backend/ml/utils.py - Logging, feature vectors, validation\")\n",
    "print(\"  ‚úì backend/ml/ndvi.py - Sentinel-2 NDVI computation\")\n",
    "print(\"  ‚úì backend/ml/features.py - Multi-source feature extraction\")\n",
    "print(\"  ‚úì backend/ml/scoring.py - Rule-based health scoring\")\n",
    "print(\"  ‚úì backend/tests/test_ml_pipeline.ipynb - This validation notebook\")\n",
    "print(\"  ‚úì docs/examples/feature_schema.json - Schema specification\")\n",
    "\n",
    "print(\"\\nüéØ KEY INSIGHTS:\")\n",
    "print(f\"  ‚Ä¢ Best performing site: {comparison_df.loc[comparison_df['Health Score'].idxmax(), 'Site']}\")\n",
    "print(f\"    Score: {comparison_df['Health Score'].max():.1%}\")\n",
    "print(f\"  ‚Ä¢ Needs attention: {comparison_df.loc[comparison_df['Health Score'].idxmin(), 'Site']}\")\n",
    "print(f\"    Score: {comparison_df['Health Score'].min():.1%}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"VALIDATION COMPLETE\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "logger.info(\"=\" * 80)\n",
    "logger.info(\"TowerGuard ML Pipeline Validation Complete\")\n",
    "logger.info(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
